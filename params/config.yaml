# --- PROJECT SETTINGS ---
project_name: "SPQA_FullVol_Ultra"
mode: "train"
method: "MC"
seed: 42

# --- MODEL ARCHITECTURE (Doubled Capacity) ---
model:
  architecture: "unet3d"
  in_channels: 1
  n_classes: 1
  # DOUBLED FILTERS: Uses more VRAM, learns much finer details
  channels: [32, 64, 128, 256, 512]
  strides: [2, 2, 2, 2]
  dropout_rate: 0.2
  image_size: [256, 256, 256]

  latent_dim: 2048
  model_path: ""

# --- DATA CONFIGURATION ---
Data:
  training_ids: "C:/Users/Lab/OneDrive/Desktop/SPQA/fold_4/training_ids.txt"
  test_ids: "C:/Users/Lab/OneDrive/Desktop/SPQA/fold_4/test_ids.txt"
  raw_data_root: "C:/Users/Lab/OneDrive/Desktop/SPQA/synthstrip_data_v1.5"
  image_size: [256, 256, 256]

# --- TRAINING HYPERPARAMETERS ---
Train:
  # AGGRESSIVE BATCH SIZE: Fills the 63GB VRAM
  # If you get OOM, drop this to 2
  batch_size: 4

  epochs: 1000
  # Increased LR because batch_size is larger (Linear Scaling Rule)
  learning_rate_gen: 0.0002

  patience: 50
  save_dir: "C:/Users/Lab/OneDrive/Desktop/SPQA/logs/checkpoints_ultra"

QC:
  enabled: True
  architecture: "vae3d"
  in_channels: 1          # VAE sees 1 channel (the mask)
  checkpoint_dir: "C:/Users/Lab/OneDrive/Desktop/SPQA/logs/vae_checkpoints"
  latent_dim: 2048